=========
NN
=========
RBF神经网络
=========
- `RBF神经网络 <https://www.zhihu.com/question/44328472>`_
- `RPROP弹性反向传播1 <http://blog.csdn.net/shenxiaolu1984/article/details/52511202>`_
- `RPROP弹性反向传播2 <http://www.mamicode.com/info-detail-1343139.html>`_
- `RPROP弹性反向传播3 <http://www.chinabaike.com/m/s/1483455.html>`_
- `cascade correlation级联算法Fahlman1 <http://www.ra.cs.uni-tuebingen.de/SNNS/UserManual/node164.html>`_
- `cascade correlation级联算法Fahlman2 <https://pdfs.semanticscholar.org/98c6/0103f3de54f1378d52ba236f8d79d2936510.pdf>`_
- `The Dynamic Decay Adjustment Algorithm <http://www.ra.cs.uni-tuebingen.de/SNNS/UserManual/node193.html#SECTION0010111000000000000000>`_
- `RBF DDA <https://papers.nips.cc/paper/946-boosting-the-performance-of-rbf-networks-with-dynamic-decay-adjustment.pdf>`_
- `SNNs <http://www.ra.cs.uni-tuebingen.de/SNNS/>`_

==========
HMM
==========
- MM马尔可夫模型: 序列的算法
- `你的外在行为只是你内在意愿的表现  HMM隐马尔可夫模型 <http://blog.csdn.net/dark_scope/article/details/61417336>`_ 
- `HMM <http://blog.csdn.net/Dark_Scope/article/details/63683686>`_  一般来说如果当前行为只受上一个的影响，我们称之为一阶马尔可夫链;

==========
IL
==========
- `Version Space and Bias <https://www.cnblogs.com/lufangtao/archive/2013/05/24/3086935.html>`_ 

==========
RL
==========
- `Introduction RL <https://www.zhihu.com/question/41775291>`_ 监督学习, 是已经有了数据和数据对应的正确标签, RL通过一次次在环境中的尝试, 获取这些数据和标签, 然后再学习通过哪些数据能够对应哪些标签, 通过学习到的这些规律, 竟可能地选择带来高分的行为.
- `RL 强化学习 <https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/1-1-A-RL/>`_ 
- `算法 行为的价值来选取特定行为的方法 <https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/1-1-B-RL-methods/>`_  使用表格学习的Q learning, sarsa, 使用神经网络学习的Deep Q network, 还有直接输出行为的 policy gradients, 又或者了解所处的环境, 想象出一个虚拟的环境并从虚拟的环境中学习.

===========
Unüberwachtes Lernen
===========
1. K-means-Clustering
2. Fuzzy-k-means-Clustering
3. Hierarchische Ballungsanalyse Sub-ballungen und Sub-sub-ballungen
4. Agglomerative Hierarchical Clustering AHC-Distanz: Nearest Neighbor Farthest Neighbor
5. COBWEB: Lernen durch inkrementelles Aufbauen und Anpassen eines Strukturbaums

============
Lerntheorie Algorithmenunabhängige Verfahren  für überwachtes induktives Lernen)
============
1. Lernmaschine
2. Überwachtes Lernen
3. Fehlermaßfuntion
4. Empirischer Fehler
5. Fehlerminimierung   Fehlerminimierung als Gradientenabstieg
6. Overfitting
7. Modellwahl
8. Boosting für Klassifikation AdaBoost
9. Kaskadierung Viola
10. PAC: Probably Approximate Correct Lernbarkeit
11. Vapnik-Chervonenkis(VC) Dimension
12. Abschäthung des Testfehlers

==============
Entscheidungsbäume
==============
1. ID3 Top down Aufbau von EB
2. Overfitting
3. C4.5
4. ID5R
5. Random Forests

===============
SVM
===============
